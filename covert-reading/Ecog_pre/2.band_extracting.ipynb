{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " #load Raw data from TDT ECoG maschine, plz run \"\"\n",
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "from scipy import signal\n",
    "import tdt\n",
    "import os\n",
    "import  wave\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from scipy.fftpack import fft\n",
    "from random import shuffle\n",
    "import h5py\n",
    "import scipy.io as scio\n",
    "import scipy.io.wavfile\n",
    "import math\n",
    "import mne\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import torch\n",
    "from torch.utils import data as Data\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "# import grad_cam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "READ IN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.load('/public/DATA/overt_reading/dataset/HS83/400/0/0_data_block_cue.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 401, 200)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='/public/DATA/overt_reading/dataset'\n",
    "train_num=[0,1,2,3,4]#写成更好看的形式\n",
    "val_num=[5]\n",
    "# test_num=[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#全频段\n",
    "class CustomDataset(Data.Dataset):\n",
    "    def __init__(self, HS, path, freq, elec, num_samples):\n",
    "        super().__init__()\n",
    "        self.data = [] # 存Ecog数据，0-59为cue，60-120为read，每一个item的shape为（1, n_freq, n_timePoint)\n",
    "        self.labels = [] # 存label，cue标记为0，read标记为1\n",
    "\n",
    "        path_elec = os.path.join(path, f'HS{HS}', str(freq), str(elec))\n",
    "     \n",
    "        for num in num_samples: # num为块的个数，tarin，test，valid取得块数4，1，1\n",
    "            # print(num)\n",
    "            cue_path = os.path.join(path_elec, f'elec{elec}_{num}_data_block_cue.npy')\n",
    "            read_path = os.path.join(path_elec, f'elec{elec}_{num}_data_block_read.npy')\n",
    "\n",
    "            if os.path.exists(cue_path) and os.path.exists(read_path):\n",
    "                elec_cue = np.load(cue_path) # (n_task, n_freq, n_timePoint) (60, 501, 375)\n",
    "                elec_read = np.load(read_path)[:,:,:elec_cue.shape[2]]  # Slice first 200 time points\n",
    "                len_cue=elec_cue.shape[0]\n",
    "                len_read=elec_read.shape[0]\n",
    "\n",
    "                for i in range(4): # 绘制前4个word的看和读的数据热图，取150~401的freq\n",
    "                    ax1=plt.subplot(2,4,i+1)\n",
    "                    # elec_cue[i]=(elec_cue[i]-np.mean(elec_cue[i],axis=1,keepdims=True))/np.std(elec_cue[i],axis=1,keepdims=True)\n",
    "                    sns.heatmap(np.log10(abs(elec_cue[i][150:,:])+1e-10),cmap='coolwarm',vmin=-1,vmax=1,cbar=False)\n",
    "                    ax1.set_xticks([])  # 清除x轴刻度\n",
    "                    ax1.set_yticks([])\n",
    "                    ax2=plt.subplot(2,4,i+5)\n",
    "                    # elec_read[i]=(elec_read[i]-np.mean(elec_read[i],axis=1,keepdims=True))/np.std(elec_read[i],axis=1,keepdims=True)\n",
    "                    sns.heatmap(np.log10(abs(elec_read[i][150:,:])+1e-10),cmap='coolwarm',vmin=-1,vmax=1,cbar=False)\n",
    "                    ax2.set_xticks([])  # 清除x轴刻度\n",
    "                    ax2.set_yticks([])\n",
    "                plt.show()\n",
    "\n",
    "                for i in range(len_cue): # 将数据添加到data数组中，并在labels数组中添加看的label=0\n",
    "                    # elec_cue[i]=(elec_cue[i]-np.mean(elec_cue[i],axis=1,keepdims=True))/np.std(elec_cue[i],axis=1,keepdims=True)\n",
    "                    # elec_cue_concat=self.extracting(elec_cue[i],freq)\n",
    "                    # elec_cue_hg=elec_cue[i][70:151,:]\n",
    "                    elec_cue_hg=elec_cue[i][150:,:]\n",
    "                    elec_cue_hg=elec_cue_hg[np.newaxis,:,:]\n",
    "                    self.data.append(elec_cue_hg)  # Append data\n",
    "                    # print(np.sum(elec_cue_concat,axis=0),1)\n",
    "                    # assert np.array_equal(np.sum(elec_cue_concat,axis=0),elec_cue[i])\n",
    "                    # self.labels.append([1,0])  # Label for cue\n",
    "                    self.labels.append(0)\n",
    "\n",
    "                for j in range(len_read): # 将数据添加到data数组中，并在labels数组中添加读的label=1\n",
    "                    # elec_read[j]=(elec_read[j]-np.mean(elec_read[j],axis=1,keepdims=True))/np.std(elec_read[j],axis=1,keepdims=True)\n",
    "                    # elec_read_concat=self.extracting(elec_read[j],freq)\n",
    "                    # elec_read_hg=elec_read[j][70:151,:]\n",
    "                    elec_read_hg=elec_read[j][150:,:]\n",
    "                    elec_read_hg=elec_read_hg[np.newaxis,:,:]\n",
    "                    self.data.append(elec_read_hg)  # Append data\n",
    "                    # assert np.array_equal(np.sum(elec_read_hg,axis=0),elec_read[j])\n",
    "                    # self.labels.append([0,1])  # Label for read\n",
    "                    self.labels.append(1)\n",
    "            #     print(len(self.data))\n",
    "            # print(len(self.data))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return a tuple of (data, label) and convert data to a PyTorch tensor\n",
    "        # print(self.data.shape)\n",
    "        return torch.tensor(abs(self.data[idx]), dtype=torch.float), torch.tensor(self.labels[idx])\n",
    "    \n",
    "    def extracting(self,stft_block,freq):\n",
    "        f=torch.arange(stft_block.shape[0])\n",
    "\n",
    "        bands = {\n",
    "            'else1': (0, 1),\n",
    "            'delta': (1, 4),\n",
    "            'theta': (4, 8),\n",
    "            'alpha': (8, 12),\n",
    "            'beta': (12, 30),\n",
    "            'gamma': (30, 150),\n",
    "            'else2': (150, freq+1)\n",
    "        }\n",
    "        band_list=[]\n",
    "        for _, (low, high) in bands.items():\n",
    "            band_data=np.zeros_like(stft_block)\n",
    "            indices = np.where((f >=low) & (f < high))\n",
    "            band_data[indices, :] = stft_block[indices, :]\n",
    "            band_list.append(band_data)\n",
    "        \n",
    "        return np.stack(band_list)###############2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "HS=86\n",
    "# print(train_num)\n",
    "train_dataset = CustomDataset(HS, PATH, 500, 7, train_num)\n",
    "val_dataset = CustomDataset(HS, PATH, 500, 7, val_num)\n",
    "# test_dataset = CustomDataset(HS, PATH, 500, 7, test_num)\n",
    "train_loader = Data.DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "val_loader = Data.DataLoader(val_dataset, batch_size=1, shuffle=True)\n",
    "# test_loader = Data.DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# print(f'{len(train_loader)}/{len(val_loader)}/{len(test_loader)}')\n",
    "print(f'{len(train_loader)}/{len(val_loader)}') # 300/120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 351, 375]) tensor([0, 0])\n"
     ]
    }
   ],
   "source": [
    "num=0\n",
    "for batch in train_loader:\n",
    "    block,gt=batch\n",
    "    print(block.shape,gt)\n",
    "    # if torch.equal(gt,torch.tensor([[0, 1]])):\n",
    "    #     num+=1\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二分类问题\n",
    "训练256个模型\n",
    "读取数据集：83号病人的datablock，time，datalabel\n",
    "datablock和datalabel作为训练集的x和y\n",
    "6个block按照4：1：1分为train，val，test\n",
    "抽取不同波段，模型的第一层为一个线性映射\n",
    "喂给模型\n",
    "绘制acc曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LinearMap(nn.Module):\n",
    "\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super(LinearMap,self).__init__()\n",
    "\n",
    "#         self.weights=nn.Parameter(torch.randn(7,1,1))\n",
    "\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # x is expected to be of shape (batch_size, 7, 401, 200)\n",
    "#         # Apply weights and sum along the channel dimension\n",
    "#         x_weighted = (x * self.weights).sum(dim=1,keepdim=True)  # Resulting shape: (batch_size, 401, 200)\n",
    "#         # x_weighted=torch.transpose(x_weighted,1,2)\n",
    "#   # Resulting shape: (batch_size, 200, out_channels)\n",
    "\n",
    "#         return x_weighted\n",
    "# batch_size = 2 # Example batch size\n",
    "# bands = 7\n",
    "# freq=401     # Example number of bands\n",
    "# out_channels = 64  # Desired output channels for LSTM processing\n",
    "# input_tensor = torch.randn(batch_size, bands, freq, 200)  # Example input tensor\n",
    "\n",
    "# model = LinearMap()\n",
    "# output_tensor = model(input_tensor)\n",
    "# print(output_tensor.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.models import ResNet50_Weights\n",
    "class ECOGRes50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECOGRes50, self).__init__()\n",
    "        # self.conv7to1 = nn.Conv2d(7, 1, kernel_size=1, stride=1,padding=0, bias=False)\n",
    "        self.res50= models.resnet50()\n",
    "        self.res50.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        num_ftrs = self.res50.fc.in_features\n",
    "        self.res50.fc = nn.Sequential(nn.Linear(num_ftrs,1, bias=False),\n",
    "                                    )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # x = self.conv7to1(x)\n",
    "        x=self.res50(x)\n",
    "        return x\n",
    "    \n",
    "model = ECOGRes50()\n",
    "\n",
    "# 准备输入数据\n",
    "# 假设原始数据的形状是 [2, 401, 200]\n",
    "data = torch.randn(2, 1,401, 200)\n",
    "outputs = model(data)\n",
    "print(outputs.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# class ECOGLSTM(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim=256, num_layers=4, dropout_rate=0.5):\n",
    "#         super(ECOGLSTM, self).__init__()\n",
    "#         # LSTM layer with dropout\n",
    "#         self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout_rate)\n",
    "        \n",
    "#         # Fully connected layer that maps the LSTM output to 2 outputs (for binary classification)\n",
    "#         self.fc = nn.Linear(hidden_dim, 2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Forward propagate the LSTM\n",
    "#         out, _ = self.lstm(x)  # Output shape: (batch_size, sequence_length, hidden_dim)\n",
    "        \n",
    "#         # Decode the hidden state of the last time step\n",
    "#         out = self.fc(out[:, -1, :])  # Shape: (batch_size, 2)\n",
    "        \n",
    "#         return out\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# input_dim = 200\n",
    "# hidden_dim = 100  # Example size, adjust based on your needs\n",
    "# num_layers = 4  # Example, can be adjusted\n",
    "\n",
    "# model = ECOGLSTM(401, hidden_dim, num_layers)\n",
    "# # Test input\n",
    "# test_input =output_tensor # (batch_size, sequence_length, input_dim)\n",
    "# output = model(test_input)\n",
    "# # Applying softmax to get probabilities for each class\n",
    "\n",
    "# print(output)  # Outputs probabilities for each class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5023]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class EcogBandRes(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EcogBandRes,self).__init__()\n",
    "        self.res=ECOGRes50()\n",
    "\n",
    "    def forward(self,x):\n",
    "        # x=self.linearmap(x)\n",
    "        x=self.res(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "hidden_dim = 100  # Example size, adjust based on your needs\n",
    "num_layers = 4 \n",
    "    \n",
    "batch_size = 1 # Example batch size\n",
    "bands = 7\n",
    "freq=401     # Example number of bands\n",
    "input_tensor = torch.randn(batch_size,1,401,200)\n",
    "net=EcogBandRes()\n",
    "out=net(input_tensor)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EcogBandLSTM(nn.Module):\n",
    "#     def __init__(self,freq,hidden_dim, num_layers):\n",
    "#         super(EcogBandLSTM,self).__init__()\n",
    "#         self.linearmap=LinearMap()\n",
    "#         self.lstm=ECOGLSTM(freq, hidden_dim, num_layers)\n",
    "\n",
    "#     def forward(self,x):\n",
    "#         x=self.linearmap(x)\n",
    "#         x=self.lstm(x)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9765/141488698.py:10: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm  # may raise warning about Jupyter\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import statistics\n",
    "from typing import Callable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.autonotebook import tqdm  # may raise warning about Jupyter\n",
    "from tqdm.auto import tqdm  # who needs warnings\n",
    "\n",
    "import torch, torchvision\n",
    "from torch import nn\n",
    "from torch.utils import data as Data\n",
    "class Solver(object):\n",
    "    def __init__(self,\n",
    "                 model: nn.Module,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 criterion: Callable,\n",
    "                 lr_scheduler = None,\n",
    "                 recorder: dict = None,\n",
    "                 device=None,\n",
    "                 early_stopping_patience=10):\n",
    "        device = device if device is not None else \\\n",
    "            ('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.device = device\n",
    "        self.recorder = recorder\n",
    "        \n",
    "        self.model = self.to_device(model)\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        #early stop \n",
    "        self.best_per = 0 \n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.early_stopping_counter = 0\n",
    "        self.best_val_loss = float('inf')       \n",
    "\n",
    "    def _step(self,\n",
    "              batch: tuple) -> dict:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def to_device(self, x):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return x.to(self.device)\n",
    "        elif isinstance(x, np.ndarray):\n",
    "            return torch.tensor(x, device=self.device)\n",
    "        elif isinstance(x, nn.Module):\n",
    "            return x.to(self.device)\n",
    "        else:\n",
    "            raise RuntimeError(\"Data cannot transfer to correct device.\")\n",
    "\n",
    "    def to_numpy(self, x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            return x\n",
    "        elif isinstance(x, torch.Tensor):\n",
    "            return x.detach().cpu().numpy()\n",
    "        else:\n",
    "            raise RuntimeError(f\"Cannot convert type {type(x)} into numpy array.\")\n",
    "\n",
    "    def train(self,\n",
    "              epochs: int,\n",
    "              data_loader,\n",
    "              *,\n",
    "              val_loader=None,\n",
    "              is_plot=True) -> dict:             \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        val_loss_epochs = []\n",
    "        train_loss_epochs = []\n",
    "        val_acc=[]\n",
    "        tpr_list_epochs = []  # Collect TPR for each epoch\n",
    "        fpr_list_epochs = []  # Collect FPR for each epoch\n",
    "\n",
    "        pbar_train = tqdm(total=len(data_loader)*2-1, unit='block')\n",
    "        if val_loader is not None:\n",
    "            pbar_val = tqdm(total=len(val_loader), desc=f'[Validation] waiting', unit='block')\n",
    "\n",
    "        train_acc=[]\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            pbar_train.reset()\n",
    "            pbar_train.set_description(desc=f'[Train] Epoch {epoch + 1}/{epochs}')\n",
    "            epoch_loss_acc = 0\n",
    "            epoch_size = 0\n",
    "            epoch_acc=0\n",
    "    \n",
    "            \n",
    "            for batch in data_loader:\n",
    "                self.model.train()\n",
    "                # forward\n",
    "                step_dict = self._step(batch)\n",
    "                batch_size = step_dict['batch_size']\n",
    "                loss = step_dict['loss']\n",
    "                acc=step_dict['acc']\n",
    "                # backward\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "\n",
    "                # optimize\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # update information\n",
    "                loss_value = loss.item()\n",
    "                epoch_loss_acc += loss_value\n",
    "                epoch_size += batch_size\n",
    "                epoch_acc+=acc\n",
    "\n",
    "                pbar_train.update(batch_size)\n",
    "                pbar_train.set_postfix(loss=loss_value / batch_size)\n",
    "\n",
    "            epoch_avg_loss = epoch_loss_acc / epoch_size\n",
    "            epoch_avg_acc=epoch_acc/epoch_size\n",
    "            pbar_train.set_postfix(epoch_avg_loss=epoch_avg_loss)\n",
    "            train_loss_epochs.append(epoch_avg_loss)\n",
    "            train_acc.append(epoch_avg_acc)\n",
    "\n",
    "\n",
    "            if self.lr_scheduler:\n",
    "                self.lr_scheduler.step()\n",
    "\n",
    "            # validate if `val_loader` is specified\n",
    "            if val_loader is not None:\n",
    "                pbar_val.reset()\n",
    "                pbar_val.set_description(desc=f'[Validation] Epoch {epoch + 1}/{epochs}')\n",
    "                val_avg_loss,total_avg_acc,TP,TN,FP,FN, tpr_list, fpr_list= self.validate(val_loader, pbar=pbar_val,is_test=False)\n",
    "                val_loss_epochs.append(val_avg_loss)\n",
    "                val_acc.append(total_avg_acc)\n",
    "\n",
    "                tpr_list_epochs.append(tpr_list)\n",
    "                fpr_list_epochs.append(fpr_list)\n",
    "                if total_avg_acc > self.best_per:\n",
    "                    torch.save(self.model,'sig_else2_model.pth')\n",
    "                \n",
    "                if total_avg_acc > self.best_per:\n",
    "                    torch.save(self.model,'best_model.pth')\n",
    "                    self.best_per = total_avg_acc\n",
    "\n",
    "            # Early Stopping\n",
    "\n",
    "                if val_avg_loss < self.best_val_loss:\n",
    "                    self.best_val_loss = val_avg_loss\n",
    "                    self.early_stopping_counter = 0\n",
    "                else:\n",
    "                    self.early_stopping_counter += 1\n",
    "\n",
    "                if self.early_stopping_counter >= self.early_stopping_patience:\n",
    "                    print(f'Early stopping at epoch {epoch + 1}\\n')\n",
    "                    print('TP:',TP,'TN:',TN,'FP:',FP,'FN:',FN,'\\n')\n",
    "                    break\n",
    "\n",
    "        pbar_train.close()\n",
    "        if val_loader is not None:\n",
    "            pbar_val.close()\n",
    "        train_loss_epochs = torch.tensor(train_loss_epochs).numpy()\n",
    "        val_loss_epochs = torch.tensor(val_loss_epochs).numpy()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(list(range(1, epochs + 1)), train_loss_epochs, label='train')\n",
    "        if val_loader is not None:\n",
    "            plt.plot(list(range(1, epochs + 1)), val_loss_epochs, label='validation')\n",
    "        plt.legend()\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()\n",
    "        plt.close('all')\n",
    "\n",
    "        if val_loader is not None:\n",
    "            train_acc=torch.tensor(train_acc).numpy()\n",
    "            val_acc=torch.tensor(val_acc).numpy()\n",
    "            plt.figure()\n",
    "            plt.plot(list(range(1, epochs + 1)), train_acc, label='train')\n",
    "            plt.plot(list(range(1, epochs + 1)), val_acc, label='validation')\n",
    "            plt.legend()\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('ACC')\n",
    "            plt.show()\n",
    "            plt.close('all')\n",
    "\n",
    "        all_tpr = list(itertools.chain.from_iterable(tpr_list_epochs))\n",
    "        all_fpr = list(itertools.chain.from_iterable(fpr_list_epochs))\n",
    "\n",
    "        # Plot ROC curve\n",
    "        plt.figure()\n",
    "        plt.plot(all_fpr, all_tpr, marker='.')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curve')\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate AUC\n",
    "        auc = np.trapz(all_tpr, all_fpr)\n",
    "        print(f'AUC: {auc}')\n",
    "        \n",
    "    def validate(self, data_loader, *, pbar=None,is_test=False) -> float:\n",
    "        \"\"\"\n",
    "        :param pbar: when pbar is specified, do not print average loss\n",
    "        :return:\n",
    "        \"\"\"       \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        metrics_acc = {}\n",
    "        loss_acc = 0\n",
    "        size_acc = 0\n",
    "        total_acc=0\n",
    "        is_need_log = (pbar is None)  \n",
    "\n",
    "        # Initialize TP, TN, FP, FN\n",
    "        TP, TN, FP, FN = 0, 0, 0, 0  \n",
    "\n",
    "        # Initialize lists to collect TPR and FPR\n",
    "        tpr_list = []\n",
    "        fpr_list = []\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            if pbar is None:\n",
    "                pbar = tqdm(total=len(data_loader), desc=f'[Validation]', unit='block')\n",
    "\n",
    "            \n",
    "            for batch in data_loader:\n",
    "                self.model.eval()\n",
    "\n",
    "                # forward\n",
    "                pred = self.model(batch[0].to(self.device))\n",
    "                pred_mask=torch.sigmoid(pred)\n",
    "\n",
    "                pred_mask[pred_mask>0.5]=1\n",
    "                pred_mask[pred_mask<=0.5]=0\n",
    "                acc=torch.sum(pred_mask==batch[1].to(torch.int).to(self.device))\n",
    "\n",
    "                TP += ((pred_mask == 1) & (batch[1].to(self.device) == 1)).sum().item()\n",
    "                TN += ((pred_mask == 0) & (batch[1].to(self.device) == 0)).sum().item()\n",
    "                FP += ((pred_mask == 1) & (batch[1].to(self.device) == 0)).sum().item()\n",
    "                FN += ((pred_mask == 0) & (batch[1].to(self.device) == 1)).sum().item()\n",
    "\n",
    "                # Calculate TPR and FPR for each batch\n",
    "                tpr = TP / (TP + FN)\n",
    "                fpr = FP / (FP + TN)\n",
    "                tpr_list.append(tpr)\n",
    "                fpr_list.append(fpr)\n",
    "\n",
    "                step_dict = self._step(batch)\n",
    "                batch_size = step_dict['batch_size']\n",
    "                loss = step_dict['loss']\n",
    "                acc=step_dict['acc']\n",
    "                # print(acc)\n",
    "                loss_value = loss.item()\n",
    "\n",
    "                # aggregate metrics\n",
    "                metrics_acc = self._aggregate_metrics(metrics_acc, step_dict)\n",
    "\n",
    "                # update information\n",
    "                loss_acc += loss_value\n",
    "                size_acc += batch_size\n",
    "                total_acc+=acc\n",
    "                pbar.update(batch_size)\n",
    "                pbar.set_postfix(loss=loss_value)\n",
    "\n",
    "\n",
    "        val_avg_loss = loss_acc / size_acc\n",
    "        total_avg_acc=total_acc/size_acc\n",
    "        if is_test:\n",
    "            print(total_avg_acc)\n",
    "        pbar.set_postfix(val_avg_loss=val_avg_loss)\n",
    "        if is_need_log:\n",
    "            pbar.close()  # destroy newly created pbar\n",
    "            print('=' * 30 + ' Measurements ' + '=' * 30)\n",
    "            for k, v in metrics_acc.items():\n",
    "                print(f\"[{k}] {v / size_acc}\")\n",
    "        else:\n",
    "            return val_avg_loss,total_avg_acc,TP,TN,FP,FN,tpr_list, fpr_list\n",
    "\n",
    "    def _aggregate_metrics(self, metrics_acc: dict, step_dict: dict):\n",
    "        batch_size = step_dict['batch_size']\n",
    "        for k, v in step_dict.items():\n",
    "            if k[:7] == 'metric_':\n",
    "                value = v * batch_size\n",
    "                metric_name = k[7:]\n",
    "                if metric_name not in metrics_acc:\n",
    "                    metrics_acc[metric_name] = value\n",
    "                else:\n",
    "                    metrics_acc[metric_name] += value\n",
    "        return metrics_acc\n",
    "\n",
    "\n",
    "    def get_recorder(self) -> dict:\n",
    "        return self.recorder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import itertools\n",
    "# import statistics\n",
    "# from typing import Callable\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# # from tqdm import tqdm\n",
    "# from matplotlib import pyplot as plt\n",
    "# from tqdm.autonotebook import tqdm  # may raise warning about Jupyter\n",
    "# from tqdm.auto import tqdm  # who needs warnings\n",
    "\n",
    "# import torch, torchvision\n",
    "# from torch import nn\n",
    "# from torch.utils import data as Data\n",
    "# class Solver(object):\n",
    "#     def __init__(self,\n",
    "#                  model: nn.Module,\n",
    "#                  optimizer: torch.optim.Optimizer,\n",
    "#                  criterion: Callable,\n",
    "#                  lr_scheduler = None,\n",
    "#                  recorder: dict = None,\n",
    "#                  device=None):\n",
    "#         device = device if device is not None else \\\n",
    "#             ('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#         self.device = device\n",
    "#         self.recorder = recorder\n",
    "        \n",
    "#         self.model = self.to_device(model)\n",
    "#         self.optimizer = optimizer\n",
    "#         self.criterion = criterion\n",
    "#         self.lr_scheduler = lr_scheduler        \n",
    "\n",
    "#     def _step(self,\n",
    "#               batch: tuple) -> dict:\n",
    "#         raise NotImplementedError()\n",
    "\n",
    "#     def to_device(self, x):\n",
    "#         if isinstance(x, torch.Tensor):\n",
    "#             return x.to(self.device)\n",
    "#         elif isinstance(x, np.ndarray):\n",
    "#             return torch.tensor(x, device=self.device)\n",
    "#         elif isinstance(x, nn.Module):\n",
    "#             return x.to(self.device)\n",
    "#         else:\n",
    "#             raise RuntimeError(\"Data cannot transfer to correct device.\")\n",
    "\n",
    "#     def to_numpy(self, x):\n",
    "#         if isinstance(x, np.ndarray):\n",
    "#             return x\n",
    "#         elif isinstance(x, torch.Tensor):\n",
    "#             return x.detach().cpu().numpy()\n",
    "#         else:\n",
    "#             raise RuntimeError(f\"Cannot convert type {type(x)} into numpy array.\")\n",
    "\n",
    "#     def train(self,\n",
    "#               epochs: int,\n",
    "#               data_loader,\n",
    "#               *,\n",
    "#               val_loader=None,\n",
    "#               is_plot=True) -> dict:             \n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "#         val_loss_epochs = []\n",
    "#         train_loss_epochs = []\n",
    "#         val_acc=[]\n",
    "\n",
    "#         pbar_train = tqdm(total=len(data_loader)*2-1, unit='block')\n",
    "#         if val_loader is not None:\n",
    "#             pbar_val = tqdm(total=len(val_loader), desc=f'[Validation] waiting', unit='block')\n",
    "\n",
    "#         train_acc=[]\n",
    "#         for epoch in range(epochs):\n",
    "\n",
    "#             pbar_train.reset()\n",
    "#             pbar_train.set_description(desc=f'[Train] Epoch {epoch + 1}/{epochs}')\n",
    "#             epoch_loss_acc = 0\n",
    "#             epoch_size = 0\n",
    "#             epoch_acc=0\n",
    "    \n",
    "            \n",
    "#             for batch in data_loader:\n",
    "#                 self.model.train()\n",
    "#                 # forward\n",
    "#                 step_dict = self._step(batch)\n",
    "#                 batch_size = step_dict['batch_size']\n",
    "#                 loss = step_dict['loss']\n",
    "#                 acc=step_dict['acc']\n",
    "#                 # backward\n",
    "#                 self.optimizer.zero_grad()\n",
    "#                 loss.backward()\n",
    "\n",
    "#                 # optimize\n",
    "#                 self.optimizer.step()\n",
    "\n",
    "#                 # update information\n",
    "#                 loss_value = loss.item()\n",
    "#                 epoch_loss_acc += loss_value\n",
    "#                 epoch_size += batch_size\n",
    "#                 epoch_acc+=acc\n",
    "\n",
    "#                 pbar_train.update(batch_size)\n",
    "#                 pbar_train.set_postfix(loss=loss_value / batch_size)\n",
    "\n",
    "#             epoch_avg_loss = epoch_loss_acc / epoch_size\n",
    "#             epoch_avg_acc=epoch_acc/epoch_size\n",
    "#             pbar_train.set_postfix(epoch_avg_loss=epoch_avg_loss)\n",
    "#             train_loss_epochs.append(epoch_avg_loss)\n",
    "#             train_acc.append(epoch_avg_acc)\n",
    "\n",
    "#             if self.lr_scheduler:\n",
    "#                 self.lr_scheduler.step()\n",
    "\n",
    "#             # validate if `val_loader` is specified\n",
    "#             if val_loader is not None:\n",
    "#                 pbar_val.reset()\n",
    "#                 pbar_val.set_description(desc=f'[Validation] Epoch {epoch + 1}/{epochs}')\n",
    "#                 val_avg_loss ,total_avg_acc= self.validate(val_loader, pbar=pbar_val,is_test=False)\n",
    "#                 val_loss_epochs.append(val_avg_loss)\n",
    "#                 val_acc.append(total_avg_acc)\n",
    "\n",
    "#         pbar_train.close()\n",
    "#         if val_loader is not None:\n",
    "#             pbar_val.close()\n",
    "#         train_loss_epochs = torch.tensor(train_loss_epochs).numpy()\n",
    "#         val_loss_epochs = torch.tensor(val_loss_epochs).numpy()\n",
    "\n",
    "#         plt.figure()\n",
    "#         plt.plot(list(range(1, epochs + 1)), train_loss_epochs, label='train')\n",
    "#         if val_loader is not None:\n",
    "#             plt.plot(list(range(1, epochs + 1)), val_loss_epochs, label='validation')\n",
    "#         plt.legend()\n",
    "#         plt.xlabel('Epochs')\n",
    "#         plt.ylabel('Loss')\n",
    "#         plt.show()\n",
    "#         plt.close('all')\n",
    "\n",
    "#         if val_loader is not None:\n",
    "#             train_acc=torch.tensor(train_acc).numpy()\n",
    "#             val_acc=torch.tensor(val_acc).numpy()\n",
    "#             plt.figure()\n",
    "#             plt.plot(list(range(1, epochs + 1)), train_acc, label='train')\n",
    "#             plt.plot(list(range(1, epochs + 1)), val_acc, label='validation')\n",
    "#             plt.legend()\n",
    "#             plt.xlabel('Epochs')\n",
    "#             plt.ylabel('ACC')\n",
    "#             plt.show()\n",
    "#             plt.close('all')\n",
    "#         print(self.model)\n",
    "#         torch.save(self.model, 'ttttmodel.pth')\n",
    "        \n",
    "\n",
    "\n",
    "#     def validate(self, data_loader, *, pbar=None,is_test=False) -> float:\n",
    "#         \"\"\"\n",
    "#         :param pbar: when pbar is specified, do not print average loss\n",
    "#         :return:\n",
    "#         \"\"\"       \n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "#         metrics_acc = {}\n",
    "#         loss_acc = 0\n",
    "#         size_acc = 0\n",
    "#         total_acc=0\n",
    "#         is_need_log = (pbar is None)        \n",
    "#         with torch.no_grad():\n",
    "#             if pbar is None:\n",
    "#                 pbar = tqdm(total=len(data_loader), desc=f'[Validation]', unit='block')\n",
    "\n",
    "            \n",
    "#             for batch in data_loader:\n",
    "#                 self.model.eval()\n",
    "\n",
    "#                 # forward\n",
    "#                 pred = self.model(batch[0].to(self.device))\n",
    "#                 pred_mask=torch.sigmoid(pred)\n",
    "#                 # print(batch[1],pred_mask)\n",
    "#                 pred_mask[pred_mask>0.5]=1\n",
    "#                 pred_mask[pred_mask<=0.5]=0\n",
    "#                 acc=torch.sum(pred_mask==batch[1].to(torch.int).to(self.device))\n",
    "#                 # print(acc)\n",
    "#                 step_dict = self._step(batch)\n",
    "#                 batch_size = step_dict['batch_size']\n",
    "#                 loss = step_dict['loss']\n",
    "#                 acc=step_dict['acc']\n",
    "#                 # print(acc)\n",
    "#                 loss_value = loss.item()\n",
    "\n",
    "#                 # aggregate metrics\n",
    "#                 metrics_acc = self._aggregate_metrics(metrics_acc, step_dict)\n",
    "\n",
    "#                 # update information\n",
    "#                 loss_acc += loss_value\n",
    "#                 size_acc += batch_size\n",
    "#                 total_acc+=acc\n",
    "#                 pbar.update(batch_size)\n",
    "#                 pbar.set_postfix(loss=loss_value)\n",
    "\n",
    "\n",
    "#         val_avg_loss = loss_acc / size_acc\n",
    "#         total_avg_acc=total_acc/size_acc\n",
    "#         if is_test:\n",
    "#             print(total_avg_acc)\n",
    "#         pbar.set_postfix(val_avg_loss=val_avg_loss)\n",
    "#         if is_need_log:\n",
    "#             pbar.close()  # destroy newly created pbar\n",
    "#             print('=' * 30 + ' Measurements ' + '=' * 30)\n",
    "#             for k, v in metrics_acc.items():\n",
    "#                 print(f\"[{k}] {v / size_acc}\")\n",
    "#         else:\n",
    "#             return val_avg_loss,total_avg_acc\n",
    "\n",
    "#     def _aggregate_metrics(self, metrics_acc: dict, step_dict: dict):\n",
    "#         batch_size = step_dict['batch_size']\n",
    "#         for k, v in step_dict.items():\n",
    "#             if k[:7] == 'metric_':\n",
    "#                 value = v * batch_size\n",
    "#                 metric_name = k[7:]\n",
    "#                 if metric_name not in metrics_acc:\n",
    "#                     metrics_acc[metric_name] = value\n",
    "#                 else:\n",
    "#                     metrics_acc[metric_name] += value\n",
    "#         return metrics_acc\n",
    "\n",
    "\n",
    "#     def get_recorder(self) -> dict:\n",
    "#         return self.recorder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# import tensorflow as tf\n",
    "\n",
    "# class LabSolver(Solver):\n",
    "#     def _step(self, batch) -> dict:\n",
    "#         block, gt = batch\n",
    "\n",
    "#         block = self.to_device(block)  # [B, C=1, H, W]\n",
    "#         gt = self.to_device(gt)  # [B, C=1, H, W]\n",
    "        \n",
    "#         B, C, H, W = block.shape\n",
    "\n",
    "#         pred = self.model(block)  # [B, C=1, H, W]\n",
    "#         gt = gt.view(B,1)\n",
    "#         loss = self.criterion(pred, gt.to(torch.float32))\n",
    "\n",
    "#         threshold=0.5\n",
    "#         pred_mask=torch.sigmoid(pred)\n",
    "#         pred_mask[pred_mask>threshold]=1\n",
    "#         pred_mask[pred_mask<=threshold]=0\n",
    "#         acc=torch.sum(pred_mask==gt.to(torch.int))\n",
    "#         # mask=torch.argmax(pred_mask,dim=1)\n",
    "#         # one_hot_pred = F.one_hot(mask, num_classes=pred_mask.shape[1])\n",
    "\n",
    "#         # assert one_hot_pred.shape==gt.shape\n",
    "#         # acc=torch.sum(one_hot_pred==gt)/2\n",
    "    \n",
    "\n",
    "#         step_dict = {\n",
    "#             'loss': loss,\n",
    "#             'batch_size': B,\n",
    "#             'acc':acc\n",
    "#         }\n",
    "\n",
    "#         return step_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LabSolver(Solver):\n",
    "    def _step(self, batch) -> dict:\n",
    "        block, gt = batch\n",
    "\n",
    "        block = self.to_device(block)  # [B, C=1, H, W]\n",
    "        gt = self.to_device(gt)  # [B, C=1, H, W]\n",
    "        \n",
    "        B, C, H, W = block.shape\n",
    "\n",
    "        pred = self.model(block)  # [B, C=1, H, W]\n",
    "        gt = gt.view(B,1)\n",
    "        loss = self.criterion(pred, gt.to(torch.float32))\n",
    "\n",
    "        threshold=0.5\n",
    "        pred_mask=torch.sigmoid(pred)\n",
    "        pred_mask[pred_mask>threshold]=1\n",
    "        pred_mask[pred_mask<=threshold]=0\n",
    "        acc=torch.sum(pred_mask==gt.to(torch.int))\n",
    "        # mask=torch.argmax(pred_mask,dim=1)\n",
    "        # one_hot_pred = F.one_hot(mask, num_classes=pred_mask.shape[1])\n",
    "\n",
    "        # assert one_hot_pred.shape==gt.shape\n",
    "        # acc=torch.sum(one_hot_pred==gt)/2\n",
    "    \n",
    "\n",
    "        step_dict = {\n",
    "            'loss': loss,\n",
    "            'batch_size': B,\n",
    "            'acc':acc\n",
    "        }\n",
    "\n",
    "        return step_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net=EcogBandRes()\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=0.5)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.95)\n",
    "\n",
    "# solver = LabSolver(\n",
    "#     model = net,\n",
    "#     optimizer = optimizer,\n",
    "#     criterion = nn.BCEWithLogitsLoss(),\n",
    "#     lr_scheduler=lr_scheduler\n",
    "# )\n",
    "# print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/ecog/lib/python3.12/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EcogBandRes(\n",
      "  (res): ECOGRes50(\n",
      "    (res50): ResNet(\n",
      "      (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=2048, out_features=1, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net=EcogBandRes()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.95)\n",
    "\n",
    "solver = LabSolver(\n",
    "    model = net,\n",
    "    optimizer = optimizer,\n",
    "    criterion = nn.BCEWithLogitsLoss(),\n",
    "    lr_scheduler=lr_scheduler\n",
    ")\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m solver\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[1;32m      2\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, \n\u001b[0;32m----> 3\u001b[0m     data_loader\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_loader\u001b[49m,\n\u001b[1;32m      4\u001b[0m     val_loader\u001b[38;5;241m=\u001b[39mval_loader\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "solver.train(\n",
    "    epochs=2, \n",
    "    data_loader=train_loader,\n",
    "    val_loader=val_loader\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Validation]: 100%|██████████| 120/120 [00:02<00:00, 57.14block/s, val_avg_loss=3.74]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5000, device='cuda:0')\n",
      "============================== Measurements ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "solver.validate(\n",
    "    data_loader=val_loader,\n",
    "    is_test=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Validation]: 100%|██████████| 120/120 [00:02<00:00, 50.17block/s, val_avg_loss=1.23]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5000, device='cuda:0')\n",
      "============================== Measurements ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_load=torch.load('sig_else2_model.pth')\n",
    "solver.model = model_load\n",
    "solver.validate(\n",
    "    data_loader=val_loader,\n",
    "    is_test=True\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver.validate(\n",
    "#     data_loader=test_loader,\n",
    "# #     is_test=True\n",
    "    \n",
    "# # )\n",
    "# for batch in test_loader:\n",
    "#     print(solver.model(batch[0].to(solver.device)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
